Model Accuracy:

classifier = xgboost(data = data, label = label, nrounds = 20, num_class = 7, objective = "multi:softmax", verbose = 2)

y_pred Confusion Matrix

       0    1    2    3    4    5    6
  0  580   46    0    0    0    4    1
  1   42  686    1    0    0   34    7
  2    0    1  652   17    3   11   44
  3    0    0   22  785    0    0    5
  4    0    0    0    2 1008    2    0
  5    3   58   17    0    0  452   77
  6    0   11   53    6    0   55  505
  
 >>>Confusion matrix calculated accuracy
 accuracy = (cm2[1,1] + cm2[2,2] + cm2[3,3] + cm2[4,4] + cm2[5,5] + cm2[6,6]) / (cm2[1,1] + cm2[1,2] + cm2[1,3] + cm2[1,4]+ cm2[1,5] + cm2[1,6] + 
                                                                                  cm2[2,1] + cm2[2,2] + cm2[2,3] + cm2[2,4]+ cm2[2,5] + cm2[2,6] + 
                                                                                  cm2[3,1] + cm2[3,2] + cm2[3,3] + cm2[3,4]+ cm2[3,5] + cm2[3,6] + 
                                                                                  cm2[4,1] + cm2[4,2] + cm2[4,3] + cm2[4,4]+ cm2[4,5] + cm2[4,6] + 
                                                                                  cm2[5,1] + cm2[5,2] + cm2[5,3] + cm2[5,4]+ cm2[5,5] + cm2[5,6] + 
                                                                                  cm2[6,1] + cm2[6,2] + cm2[6,3] + cm2[6,4]+ cm2[6,5] + cm2[6,6])
 > accuracy
[1] 0.9405784


>>>K-Folds Cross Validation Accuracy Scoring

folds = createFolds(training_set$NObeyesdad, k = 10)
#lapply (list apply) apply the function to our list (folds) x is each fold
cv = lapply(folds, function(x) {
  training_fold = training_set[-x, ]
  test_fold = test_set[x, ]
  # mode(test_fold) <- 'double'
  classifier = xgboost(data = as.matrix(training_set[,-32]), label = training_set$NObeyesdad, nrounds = 20, num_class = 7, objective = "multi:softmax", verbose = 2)
  y_pred = predict(classifier, newdata = as.matrix(test_fold[,-32]))
  # y_pred = (y_pred >= 0.5) Only needed for binomial classification
  cm = table(as.matrix(test_fold[, 32]), y_pred)
  # Need to add the rest of the accuracy calculation cm[3,3] cm[4,4] etc
  accuracy = (cm[1,1] + cm[2,2] + cm[3,3] + cm[4,4] + cm[5,5] + cm[6,6]) / (cm[1,1] + cm[1,2] + cm[1,3] + cm[1,4]+ cm[1,5] + cm[1,6] + 
                                                                              cm[2,1] + cm[2,2] + cm[2,3] + cm[2,4]+ cm[2,5] + cm[2,6] + 
                                                                              cm[3,1] + cm[3,2] + cm[3,3] + cm[3,4]+ cm[3,5] + cm[3,6] + 
                                                                              cm[4,1] + cm[4,2] + cm[4,3] + cm[4,4]+ cm[4,5] + cm[4,6] + 
                                                                              cm[5,1] + cm[5,2] + cm[5,3] + cm[5,4]+ cm[5,5] + cm[5,6] + 
                                                                              cm[6,1] + cm[6,2] + cm[6,3] + cm[6,4]+ cm[6,5] + cm[6,6])
  return(accuracy)
})
accuracy = mean(as.numeric(cv))

> accuracy
[1] 0.9405719
